# YOLOv11-Pose Teacher Behavior Analysis SystemYOLOv11

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)[![æ¡æ¬¾:](https://img.shields.io/badge/License-MIT-yellow.svg)] (https://opensource.org/licenses/MIT)
[![Python 3.8+   Python 3.8](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.5+-green.svg)](https://opencv.org/)[! [OpenCV] (https://img.shields.io/badge/opencv - 4.5 -green.svg)] (https://opencv.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.7+-red.svg)](https://pytorch.org/)[! [PyTorch] (https://img.shields.io/badge/PyTorch-1.7 -red.svg)] (https://pytorch.org/)

An intelligent system for analyzing teacher behaviors in classroom videos using YOLOv11 pose estimation technology. This system can automatically identify, track, and evaluate various teaching activities including writing on board, explaining, interacting with students, moving around, and standing.åŸºäºYOLOv11å§¿æ€ä¼°è®¡æŠ€æœ¯çš„è¯¾å ‚è§†é¢‘æ•™å¸ˆè¡Œä¸ºåˆ†ææ™ºèƒ½ç³»ç»Ÿè¯¥ç³»ç»Ÿå¯ä»¥è‡ªåŠ¨è¯†åˆ«ã€è·Ÿè¸ªå’Œè¯„ä¼°å„ç§æ•™å­¦æ´»åŠ¨ï¼ŒåŒ…æ‹¬åœ¨é»‘æ¿ä¸Šå†™å­—ã€è§£é‡Šã€ä¸å­¦ç”Ÿäº’åŠ¨ã€èµ°åŠ¨å’Œç«™ç«‹ã€‚

## ğŸ¯ Features   ##ğŸ¯äº§å“ç‰¹ç‚¹

### Core Analysis Capabilitiesæ ¸å¿ƒåˆ†æèƒ½åŠ›
- **Pose Detection**: Real-time human pose estimation using YOLOv11 models- **å§¿æ€æ£€æµ‹**ï¼šä½¿ç”¨YOLOv11æ¨¡å‹è¿›è¡Œå®æ—¶äººä½“å§¿æ€ä¼°è®¡
- **Behavior Recognition**: Automatic identification of 7 types of teaching behaviors:- **è¡Œä¸ºè¯†åˆ«**ï¼šè‡ªåŠ¨è¯†åˆ«7ç§æ•™å­¦è¡Œä¸ºï¼š
  - ğŸ“ **Writing** (æ¿ä¹¦) - Writing on blackboard/whiteboard-ğŸ“**ä¹¦å†™**()-é»‘æ¿/ç™½æ¿ä¹¦å†™
  - ğŸ’¬ **Explaining** (è®²è§£) - Lecturing and explaining content-ğŸ’¬**è®²è§£**(0.001)-è®²è§£å†…å®¹
  - ğŸ¤ **Interacting** (äº’åŠ¨) - Interacting with students-ğŸ¤**äº’åŠ¨** -ä¸å­¦ç”Ÿäº’åŠ¨
  - ğŸš¶ **Moving** (èµ°åŠ¨) - Walking around the classroom-ğŸš¶**ç§»åŠ¨** -åœ¨æ•™å®¤é‡Œèµ°åŠ¨
  - ğŸ§ **Standing** (ç«™ç«‹) - Standing in place-ğŸ§**ç«™ç«‹** -åŸåœ°ç«™ç«‹
  - ğŸ‘‹ **Pointing** (æŒ‡å‘) - Pointing gestures-ğŸ‘‹**æŒ‡å‘**ï¼ˆé½å£°ï¼‰-æŒ‡å‘æ‰‹åŠ¿
  - âœ‹ **Raising Hand** (ä¸¾æ‰‹) - Raising hand gestures-âœ‹**ä¸¾æ‰‹**ï¼ˆè‹±æ–‡ï¼‰-ä¸¾æ‰‹ç¤ºæ„

### Advanced Features   é«˜çº§åŠŸèƒ½
- **Pose Smoothing**: Advanced smoothing algorithms to reduce detection noise- **å§¿æ€å¹³æ»‘**ï¼šå…ˆè¿›çš„å¹³æ»‘ç®—æ³•ï¼Œä»¥å‡å°‘æ£€æµ‹å™ªå£°
- **Behavior State Machine**: Intelligent state management for behavior transitions- **è¡Œä¸ºçŠ¶æ€æœº**ï¼šè¡Œä¸ºè½¬æ¢çš„æ™ºèƒ½çŠ¶æ€ç®¡ç†
- **Adaptive Frame Sampling**: Dynamic frame rate adjustment for optimal performance- **è‡ªé€‚åº”å¸§é‡‡æ ·**ï¼šåŠ¨æ€å¸§ç‡è°ƒæ•´çš„æœ€ä½³æ€§èƒ½
- **Comprehensive Analytics**: Detailed behavioral metrics and statistics-ç»¼åˆåˆ†æï¼šè¯¦ç»†çš„è¡Œä¸ºæŒ‡æ ‡å’Œç»Ÿè®¡æ•°æ®
- **Visual Reports**: Rich visualizations and charts for analysis results- **å¯è§†åŒ–æŠ¥å‘Š**ï¼šä¸°å¯Œçš„å¯è§†åŒ–å’Œå›¾è¡¨åˆ†æç»“æœ
- **Batch Processing**: Support for processing multiple videos simultaneously- **æ‰¹å¤„ç†**ï¼šæ”¯æŒåŒæ—¶å¤„ç†å¤šä¸ªè§†é¢‘
- **GPU Acceleration**: CUDA support for faster processing- **GPUåŠ é€Ÿ**:CUDAæ”¯æŒæ›´å¿«çš„å¤„ç†

### Output Formats   
- ğŸ“Š **Comprehensive Reports**: JSON format with detailed metrics-ğŸ“Š**ç»¼åˆæŠ¥å‘Š**:JSONæ ¼å¼ï¼Œè¯¦ç»†æŒ‡æ ‡
- ğŸ“ˆ **Enhanced Charts**: Beautiful matplotlib visualizations-ğŸ“ˆ**å¢å¼ºçš„å›¾è¡¨**ï¼šç¾ä¸½çš„matplotlibå¯è§†åŒ–
- ğŸ¥ **Annotated Videos**: Output videos with pose and behavior annotations-ğŸ¥**æ³¨é‡Šè§†é¢‘**ï¼šè¾“å‡ºè§†é¢‘ä¸å§¿åŠ¿å’Œè¡Œä¸ºæ³¨é‡Š
- ğŸ“‹ **Teaching Suggestions**: AI-generated recommendations for improvement-ğŸ“‹**æ•™å­¦å»ºè®®**ï¼šäººå·¥æ™ºèƒ½ç”Ÿæˆçš„æ”¹è¿›å»ºè®®

## ğŸ“¦ Installation   

### Prerequisites   
- Python 3.8+   - Python 3.8
- NVIDIA GPU (recommended for better performance)- NVIDIA GPUï¼ˆæ¨èæ›´å¥½çš„æ€§èƒ½ï¼‰
- CUDA toolkit (for GPU acceleration)CUDAå·¥å…·åŒ…ï¼ˆç”¨äºGPUåŠ é€Ÿï¼‰

### Setup Environment   

1. **Clone the repository**1. 
   ```bash   â€â€œbash
   git clone https://github.com/GDUE-DVL/yolov11pose_teacher_analysis.gitGit
   cd yolov11pose_teacher_analysis
   ```

2. **Create virtual environment**2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
   ```bash   â€â€œbash
   python -m venv venv
   
   # On Windows   #åœ¨Windowsä¸Š
   venv\Scripts\activate   venv \ \æ¿€æ´»è„šæœ¬
   
   # On Linux/macOS   #åœ¨Linux/macOSä¸Š
   source venv/bin/activate   æºvenv / bin /æ¿€æ´»
   ```

3. **Install dependencies**3. * * * *å®‰è£…ä¾èµ–å…³ç³»
   ```bash   â€â€œbash
   pip install -r requirements.txtPIP install -r requirements.txt
   ```

4. **Download pre-trained models**4. **ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹**
   
   You need to download YOLOv11 pose estimation models:æ‚¨éœ€è¦ä¸‹è½½YOLOv11å§¿æ€ä¼°è®¡æ¨¡å‹ï¼š
   - `yolov8n-pose.pt` (lightweight, faster)- ' yolov8n-pose.pt 'ï¼ˆè½»é‡çº§ï¼Œæ›´å¿«ï¼‰
   - `yolov8x-pose.pt` (more accurate, slower)â€˜ yolov8x-pose.pt â€™ï¼ˆæ›´å‡†ç¡®ï¼Œæ›´æ…¢ï¼‰
   
   Place these files in the project root directory.å°†è¿™äº›æ–‡ä»¶æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸­ã€‚

## ğŸš€ Quick Start   ##ğŸš€å¿«é€Ÿå…¥é—¨

### Single Video Analysis   å•è§†é¢‘åˆ†æ

```bash   â€â€œbash
python teacher_evaluation.py --video_path your_video.mp4 --model_path yolov8n-pose.ptâ€”â€”video_path your_video.mp4â€”â€”model_path yolov8n-pose.pt
```

### Batch Processing   æ‰¹å¤„ç†

```bash   â€â€œbash
python analyze_batch.py /path/to/video/directory --output /path/to/outputPython analyze_batch.py /path/to/video/directoryâ€”â€”output /path/to/output
```

### Adaptive Analysis (Recommended)è‡ªé€‚åº”åˆ†æï¼ˆæ¨èï¼‰

```bash   â€â€œbash
python analyze_teacher_adaptive.py your_video.mp4 --batch_size 10 --initial_skip_frames 5Python: analyze_teacher_adaptive.py your_video.mp4â€”â€”batch_size 10â€”â€”initial_skip_frames
```

### Enhanced Visualizationå¢å¼ºçš„å¯è§†åŒ–

```bash   â€â€œbash
python enhanced_chart.py your_report.jsonPython enhanced_chart.py
```

## ğŸ“ Project Structure   ##ğŸ“é¡¹ç›®ç»“æ„

```
yolov11pose_teacher_analysis/
â”œâ”€â”€ ğŸ“„ teacher_evaluation.py      # Main analysis engineâ”œâ”€â”€ğŸ“„teacher_evaluation.py #ä¸»åˆ†æå¼•æ“
â”œâ”€â”€ ğŸ“„ analyze_batch.py           # Batch processing script
â”œâ”€â”€ ğŸ“„ analyze_teacher_adaptive.py # Adaptive frame sampling
â”œâ”€â”€ ğŸ“„ fast_analyze.py            # Fast analysis with basic features
â”œâ”€â”€ ğŸ“„ enhanced_chart.py          # Advanced visualization generator
â”œâ”€â”€ ğŸ“„ SimpleHRNet.py             # Alternative HRNet model support
â”œâ”€â”€ ğŸ“„ requirements.txt           # Python dependencies
â”œâ”€â”€ ğŸ“„ README.md                  # This file
â”œâ”€â”€ ğŸ—ï¸ models/                    # Model files (download separately)
â”‚   â”œâ”€â”€ yolov8n-pose.pt
â”‚   â””â”€â”€ yolov8x-pose.pt
â”œâ”€â”€ ğŸ“ results/                   # Output directory (auto-created)
â””â”€â”€ ğŸ“ cache/                     # Cache directory (auto-created)
```

## ğŸ› ï¸ Core Components

### 1. TeacherEvaluator Class
The main analysis engine with the following key methods:åˆ†æå¼•æ“ä¸»è¦æœ‰ä»¥ä¸‹å‡ ä¸ªå…³é”®æ–¹æ³•ï¼š

```python   â€â€œpython
# Core functionality
- evaluate_video()                    # Main video analysis
- evaluate_video_adaptive()           # Adaptive frame sampling
- process_frame()                     # Single frame processing
- identify_teaching_behavior()        # Behavior classification
- generate_comprehensive_report()     # Report generation
```

### 2. PoseSmoother Class
Advanced pose smoothing using Savitzky-Golay filter:

```python
- update(person_id, points)          # Update pose data
- get_smoothed_points(person_id)     # Get smoothed coordinates
```

### 3. BehaviorStateMachine Class
Intelligent behavior state management:æ™ºèƒ½è¡Œä¸ºçŠ¶æ€ç®¡ç†ï¼š

```python
- update(new_behavior, confidence)   # Update behavior state
- get_state()                        # Get current state
- reset()                            # Reset state machine
```

## ğŸ“Š Analysis Metrics

### Behavioral Metrics
- **Time Distribution**: Percentage of time spent on each behavior
- **Activity Level**: Overall movement and engagement metrics
- **Transition Analysis**: Behavior change patterns
- **Posture Analysis**: Upper/lower body coordination
- **Teaching Effectiveness**: Derived teaching quality indicators

### Performance Metrics
- **Processing Speed**: Frames per second analysis
- **Detection Confidence**: Average pose detection confidence
- **Stability**: Pose tracking stability metrics
- **Memory Usage**: GPU and RAM utilization

## ğŸ¨ Visualization Features

The system generates comprehensive visualizations including:

- **Timeline Charts**: Behavior sequences over time
- **Distribution Pie Charts**: Behavior time proportions
- **Transition Heatmaps**: Behavior change patterns
- **Posture Analysis Plots**: Body coordination metrics
- **Performance Dashboards**: System performance metrics

## âš™ï¸ Configuration Options

### Model Selection
```bash
# Lightweight model (faster)
--model_path yolov8n-pose.pt

# High accuracy model (slower)
--model_path yolov8x-pose.pt
```

### Processing Parameters
```bash
# Frame sampling
--batch_size 10                    # Frames processed simultaneously
--initial_skip_frames 5            # Initial frame skip rate
--min_skip_frames 1                # Minimum skip rate
--max_skip_frames 10               # Maximum skip rate

# Analysis range-ğŸ“Š**ç»¼åˆæŠ¥å‘Š**:JSONæ ¼å¼ï¼Œè¯¦ç»†æŒ‡æ ‡
--start_frame 0                    # Start from specific frame
--max_frames 1000                  # Limit processing frames
```

### Output Options
```bash
--create_video                     # Generate annotated video
--time_analysis                    # Enable time-based analysis
--output_dir /path/to/output       # Custom output directory
```

## ğŸ”§ Advanced Usage

### Custom Behavior Detection

You can extend the system by adding custom behavior detection logic:

```python
def calculate_custom_behavior_score(self, keypoints_dict):
    """Custom behavior detection implementation"""
    # Your custom logic here
    return score-ğŸ“Š**ç»¼åˆæŠ¥å‘Š**:JSONæ ¼å¼ï¼Œè¯¦ç»†æŒ‡æ ‡

# Add to TeacherEvaluator class
```

### Performance Optimization

For large-scale processing:-ğŸ“Š**ç»¼åˆæŠ¥å‘Š**:JSONæ ¼å¼ï¼Œè¯¦ç»†æŒ‡æ ‡

```python
# Enable caching-ğŸ“Š**ç»¼åˆæŠ¥å‘Š**:JSONæ ¼å¼ï¼Œè¯¦ç»†æŒ‡æ ‡
use_cache=True-ğŸ“Š**ç»¼åˆæŠ¥å‘Š**:JSONæ ¼å¼ï¼Œè¯¦ç»†æŒ‡æ ‡

# Adjust batch size based on GPU memory
batch_size=16  # Increase for better GPU utilization

# Use adaptive sampling
evaluate_video_adaptive()  # Instead of evaluate_video()
```


## ğŸ¤ Contributing

We welcome contributions! Please feel free to submit issues, feature requests, or pull requests.

### Development Setup
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [YOLOv8](https://github.com/ultralytics/ultralytics) for pose estimation models
- [OpenCV](https://opencv.org/) for computer vision operations
- [PyTorch](https://pytorch.org/) for deep learning framework
- [Matplotlib](https://matplotlib.org/) for visualization

## ğŸ“ Support

For questions, issues, or contributions:
- ğŸ“§ Email: [gdue0921@163.com]
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/yolov11pose_teacher_analysis/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/yourusername/yolov11pose_teacher_analysis/discussions)

## ğŸ”® Future Roadmap

- [ ] Real-time analysis support
- [ ] Multi-teacher detection and tracking
- [ ] Integration with classroom management systems
- [ ] Mobile app for on-the-go analysis
- [ ] Cloud-based processing options
- [ ] Advanced AI coaching recommendations

---

**Made with â¤ï¸ for educators and researchers** 
